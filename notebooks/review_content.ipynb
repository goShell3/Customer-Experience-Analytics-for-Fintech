{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb0cf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting scraping and merge process...\n",
      "[INFO] Scraping CBE (com.combanketh.mobilebanking)\n",
      "[INFO] Scraping BOA (com.boa.boaMobileBanking)\n",
      "[INFO] Scraping Dashen (com.dashen.dashensuperapp)\n",
      "[INFO] Saved 1200 scraped reviews to scraped_reviews.csv\n",
      "[INFO] Looking for additional review files in 'external_reviews'\n",
      "[INFO] No additional review folder found.\n",
      "[INFO] Cleaning and merging data...\n",
      "[INFO] Final cleaned dataset saved to all_reviews_cleaned.csv (988 reviews)\n",
      "[INFO] All done.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script for scraping banking app reviews from Google Play Store\n",
    "and uploading additional CSV review files.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from google_play_scraper import Sort, reviews\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "\n",
    "# Correct Google Play App IDs\n",
    "BANK_APPS = {\n",
    "    'CBE': 'com.combanketh.mobilebanking',\n",
    "    'BOA': 'com.boa.boaMobileBanking',\n",
    "    'Dashen': 'com.dashen.dashensuperapp'\n",
    "}\n",
    "\n",
    "def scrape_app_reviews(apps: Dict[str, str], reviews_per_app: int = 400) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Scrape reviews from Google Play Store for given apps.\n",
    "    \"\"\"\n",
    "    all_reviews = []\n",
    "\n",
    "    for app_name, app_id in apps.items():\n",
    "        print(f\"[INFO] Scraping {app_name} ({app_id})\")\n",
    "        app_reviews = []\n",
    "        count = 0\n",
    "        next_token = None\n",
    "\n",
    "        while count < reviews_per_app:\n",
    "            rvs, next_token = reviews(\n",
    "                app_id,\n",
    "                lang='en',\n",
    "                country='us',\n",
    "                sort=Sort.NEWEST,\n",
    "                count=200,\n",
    "                continuation_token=next_token\n",
    "            )\n",
    "            for r in rvs:\n",
    "                app_reviews.append({\n",
    "                    'bank': app_name,\n",
    "                    'review': r['content'],\n",
    "                    'rating': r['score'],\n",
    "                    'date': r['at'].isoformat(),\n",
    "                    'source': 'Google Play'\n",
    "                })\n",
    "            count += len(rvs)\n",
    "            if not next_token:\n",
    "                break\n",
    "\n",
    "        all_reviews.extend(app_reviews[:reviews_per_app])\n",
    "\n",
    "    return all_reviews\n",
    "\n",
    "def save_reviews_to_csv(reviews_data: List[Dict[str, Any]], filename: str = \"raw_reviews.csv\"):\n",
    "    df = pd.DataFrame(reviews_data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"[INFO] Saved {len(df)} scraped reviews to {filename}\")\n",
    "\n",
    "def load_additional_reviews(folder: str = \"external_reviews\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load additional CSVs containing review data from a folder.\n",
    "    Each CSV must include: review, rating, date, bank\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] Looking for additional review files in '{folder}'\")\n",
    "    all_frames = []\n",
    "    if not os.path.exists(folder):\n",
    "        print(\"[INFO] No additional review folder found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".csv\"):\n",
    "            path = os.path.join(folder, file)\n",
    "            try:\n",
    "                df = pd.read_csv(path)\n",
    "                df['source'] = 'External'\n",
    "                all_frames.append(df)\n",
    "                print(f\"[INFO] Loaded {len(df)} reviews from {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"[WARNING] Skipping {file}: {e}\")\n",
    "\n",
    "    return pd.concat(all_frames, ignore_index=True) if all_frames else pd.DataFrame()\n",
    "\n",
    "def clean_and_merge(scraped: pd.DataFrame, additional: pd.DataFrame, output: str = \"all_reviews_cleaned.csv\"):\n",
    "    print(\"[INFO] Cleaning and merging data...\")\n",
    "    combined = pd.concat([scraped, additional], ignore_index=True)\n",
    "\n",
    "    # Drop duplicates and missing reviews\n",
    "    combined.drop_duplicates(subset='review', inplace=True)\n",
    "    combined.dropna(subset=['review', 'rating', 'date', 'bank'], inplace=True)\n",
    "\n",
    "    # Normalize date\n",
    "    combined['date'] = pd.to_datetime(combined['date'], errors='coerce').dt.date\n",
    "    combined.dropna(subset=['date'], inplace=True)\n",
    "\n",
    "    combined = combined[['review', 'rating', 'date', 'bank', 'source']]\n",
    "    combined.to_csv(output, index=False)\n",
    "    print(f\"[INFO] Final cleaned dataset saved to {output} ({len(combined)} reviews)\")\n",
    "\n",
    "def main():\n",
    "    print(\"[INFO] Starting scraping and merge process...\")\n",
    "    \n",
    "    # Step 1: Scrape from Google Play\n",
    "    scraped_data = scrape_app_reviews(BANK_APPS, reviews_per_app=400)\n",
    "    scraped_df = pd.DataFrame(scraped_data)\n",
    "    save_reviews_to_csv(scraped_data, \"scraped_reviews.csv\")\n",
    "\n",
    "    # Step 2: Load additional reviews (optional)\n",
    "    additional_df = load_additional_reviews()\n",
    "\n",
    "    # Step 3: Clean and merge\n",
    "    clean_and_merge(scraped_df, additional_df)\n",
    "\n",
    "    print(\"[INFO] All done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
