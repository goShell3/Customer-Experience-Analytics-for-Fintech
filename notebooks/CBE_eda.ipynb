{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4baa3764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found. Current working directory: D:\\CodeFiles\\Kifiya\\week2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Option 1: Use absolute path (recommended)\n",
    "file_path = os.path.abspath(\"D:/CodeFiles/Kifiya/week2/data/metadata/CBE_metadata.csv\")\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Option 2: Correct relative path (if running from week2 folder)\n",
    "df = pd.read_csv(\"./data/metadata/CBE_metadata.csv\") \n",
    "\n",
    "# Option 3: Verify path exists first\n",
    "if os.path.exists(\"../data/metadata/CBE_metadata.csv\"):\n",
    "    df = pd.read_csv(\"../data/metadata/CBE_metadata.csv\")\n",
    "else:\n",
    "    print(\"File not found. Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40c4dd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Index(['review'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_15164\\3464936328.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Drop duplicates based on 'review' text\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = df.drop_duplicates(subset=\u001b[33m'review'\u001b[39m)\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Drop rows with missing values in any critical column\u001b[39;00m\n\u001b[32m      5\u001b[39m df = df.dropna(subset=[\u001b[33m'review'\u001b[39m, \u001b[33m'rating'\u001b[39m, \u001b[33m'date'\u001b[39m, \u001b[33m'app'\u001b[39m])\n",
      "\u001b[32mD:\\CodeFiles\\Kifiya\\week2\\venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, subset, keep, inplace, ignore_index)\u001b[39m\n\u001b[32m   6821\u001b[39m \n\u001b[32m   6822\u001b[39m         inplace = validate_bool_kwarg(inplace, \u001b[33m\"inplace\"\u001b[39m)\n\u001b[32m   6823\u001b[39m         ignore_index = validate_bool_kwarg(ignore_index, \u001b[33m\"ignore_index\"\u001b[39m)\n\u001b[32m   6824\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m6825\u001b[39m         result = self[-self.duplicated(subset, keep=keep)]\n\u001b[32m   6826\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[32m   6827\u001b[39m             result.index = default_index(len(result))\n\u001b[32m   6828\u001b[39m \n",
      "\u001b[32mD:\\CodeFiles\\Kifiya\\week2\\venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, subset, keep)\u001b[39m\n\u001b[32m   6953\u001b[39m         \u001b[38;5;66;03m# Otherwise, raise a KeyError, same as if you try to __getitem__ with a\u001b[39;00m\n\u001b[32m   6954\u001b[39m         \u001b[38;5;66;03m# key that doesn't exist.\u001b[39;00m\n\u001b[32m   6955\u001b[39m         diff = set(subset) - set(self.columns)\n\u001b[32m   6956\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[32m-> \u001b[39m\u001b[32m6957\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(Index(diff))\n\u001b[32m   6958\u001b[39m \n\u001b[32m   6959\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m len(subset) == \u001b[32m1\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m self.columns.is_unique:\n\u001b[32m   6960\u001b[39m             \u001b[38;5;66;03m# GH#45236 This is faster than get_group_index below\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: Index(['review'], dtype='object')"
     ]
    }
   ],
   "source": [
    "# Drop duplicates based on 'review' text\n",
    "df = df.drop_duplicates(subset='review')\n",
    "\n",
    "# Drop rows with missing values in any critical column\n",
    "df = df.dropna(subset=['review', 'rating', 'date', 'app'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d7dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime and normalize to YYYY-MM-DD\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.date\n",
    "\n",
    "# Drop rows where date couldn't be parsed\n",
    "df = df.dropna(subset=['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for consistency\n",
    "df = df.rename(columns={\n",
    "    'review': 'review',\n",
    "    'rating': 'rating',\n",
    "    'date': 'date',\n",
    "    'app': 'bank'\n",
    "})\n",
    "\n",
    "# Add a 'source' column\n",
    "df['source'] = 'Google Play'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder and save final cleaned data\n",
    "df = df[['review', 'rating', 'date', 'bank', 'source']]\n",
    "df.to_csv(\"../data/processed/CBE_reviews_cleaned.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
